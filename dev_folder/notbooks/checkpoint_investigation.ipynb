{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ceeaf-b908-4b12-9450-11d1c88f9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bdf71-02cc-4940-a3db-4e5821b47fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path='../cloud_runs/69.55.141.119/barc/runs/barc/20241106_004918_nogit_nobranch_lr5e-05_bl1e-06_ssu0_bs16_h4_es888_nl18_we10_as1_ph1_ac1_ad1_scosine_oadam_ge1_mh0_ssnone_ss1e-02_c5/Transformer_best_eis3056_ep5856.pt'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "print(checkpoint['epoch'], checkpoint['train_loss'], checkpoint['epoch_in_session'])\n",
    "print(checkpoint['hyperparameters'])\n",
    "print(checkpoint['epoch'], checkpoint['train_loss'], checkpoint['epoch_in_session'])\n",
    "print(checkpoint['model_state_dict'].keys())\n",
    "print(checkpoint['model_state_dict']['embedding.weight'].shape, checkpoint['model_state_dict']['positional_encoding'].shape, checkpoint['model_state_dict']['grid_encoding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dda2e-a73f-46b4-bac7-c382032dd64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_tensor import analyze_tensor, visualize_tsne\n",
    "\n",
    "def generate_tensor_names(layer_num):\n",
    "    # List of tensor names with formatted layer number\n",
    "    tensor_names = [\n",
    "        f'layers.{layer_num}.attention.in_proj_weight',\n",
    "        f'layers.{layer_num}.attention.in_proj_bias',\n",
    "        f'layers.{layer_num}.attention.out_proj.weight',\n",
    "        f'layers.{layer_num}.attention.out_proj.bias',\n",
    "        f'layers.{layer_num}.norm1.weight',\n",
    "        f'layers.{layer_num}.norm1.bias',\n",
    "        f'layers.{layer_num}.norm2.weight',\n",
    "        f'layers.{layer_num}.norm2.bias',\n",
    "        f'layers.{layer_num}.feed_forward.0.weight',\n",
    "        f'layers.{layer_num}.feed_forward.0.bias',\n",
    "        f'layers.{layer_num}.feed_forward.3.weight',\n",
    "        f'layers.{layer_num}.feed_forward.3.bias'\n",
    "    ]\n",
    "    return tensor_names\n",
    "\n",
    "def analyze_layer_tensors(checkpoint, layer_num):\n",
    "    # Generate tensor names for the specified layer\n",
    "    tensor_names = generate_tensor_names(layer_num)\n",
    "\n",
    "    # Loop through each tensor name\n",
    "    for name in tensor_names:\n",
    "        # Get the tensor from the checkpoint\n",
    "        tensor = checkpoint['model_state_dict'][name]\n",
    "        \n",
    "        # Call the analyze_tensor function\n",
    "        analyze_tensor(tensor, f'{name}, {tensor.shape}')\n",
    "\n",
    "def analyze_layer_tensors_vertical(checkpoint, names, layers_count, stack=True):\n",
    "    # Generate tensor names for the specified layer\n",
    "    tensor_names = [f'layers.{layer_num}.{name}' for layer_num in range(layers_count) for name in names]\n",
    "\n",
    "    print('tensor_names', tensor_names)\n",
    "\n",
    "    # Get the tensor from the checkpoint\n",
    "    if stack:\n",
    "        tensor = torch.stack([checkpoint['model_state_dict'][name] for name in tensor_names])\n",
    "    else:\n",
    "        tensor = torch.cat([checkpoint['model_state_dict'][name] for name in tensor_names], dim = 1)\n",
    "    \n",
    "    # Call the analyze_tensor function\n",
    "    analyze_tensor(tensor, f'{names}, {tensor.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1873a8-754b-4f0c-8566-757fccde0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_tensor(checkpoint['model_state_dict']['embedding.weight'], 'embedding.weight')\n",
    "visualize_tsne(checkpoint['model_state_dict']['embedding.weight'], 'embedding.weight', perplexity=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b832e-389e-4ef5-b107-4e73c2df4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_tensor(checkpoint['model_state_dict']['fc_out.weight'], 'fc_out.weight')\n",
    "\n",
    "analyze_tensor(checkpoint['model_state_dict']['fc_out.bias'], 'fc_out.bias')\n",
    "\n",
    "visualize_tsne(checkpoint['model_state_dict']['fc_out.weight'], 'fc_out.weight', perplexity=5)\n",
    "\n",
    "# ts.show(checkpoint['model_state_dict']['fc_out.bias'].unsqueeze(0), interpolation='nearest', figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf90810-6fde-4bfc-8b31-6ac0b5d0a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize positional encoding\n",
    "analyze_tensor(checkpoint['model_state_dict']['positional_encoding'], 'positional_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595d4c4-9b9b-4c0e-8aaa-d028bf06873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize grid encoding\n",
    "analyze_tensor(checkpoint['model_state_dict']['grid_encoding'], 'grid_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d930bd-311e-434b-af3c-1946cac1262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['model_state_dict']['grid_scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353ea95-3ca2-496b-b93c-06f29eefad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_layer_tensors_vertical(checkpoint, ('norm1.weight', 'norm2.weight'), 18)\n",
    "analyze_layer_tensors_vertical(checkpoint, ('norm1.bias', 'norm1.bias'), 18)\n",
    "\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('attention.in_proj_weight', ), 18, stack=False)\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('attention.out_proj.weight', ), 18, stack=False)\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('attention.in_proj_bias', ), 18)\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('attention.out_proj.bias', ), 18)\n",
    "\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('feed_forward.0.weight', ), 18, stack=False)\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('feed_forward.3.weight', ), 18, stack=False)\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('feed_forward.0.bias', ), 18)\n",
    "# analyze_layer_tensors_vertical(checkpoint, ('feed_forward.3.bias', ), 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894bc135-41ef-441c-ab18-a2997d58ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_number = 0\n",
    "analyze_layer_tensors(checkpoint, layer_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
