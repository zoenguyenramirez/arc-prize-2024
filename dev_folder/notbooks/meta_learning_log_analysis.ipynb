{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94fe05-4904-4750-a921-a6ae758fcccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def read_log_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "def split_into_sections(content):\n",
    "    # Split at each occurrence of \"Batch[*]dataset[*]\", but keep the delimiter\n",
    "    pattern = r'(?=Batch\\[\\d+\\]dataset\\[\\d+\\])'\n",
    "    sections = re.split(pattern, content)\n",
    "    \n",
    "    # Filter out empty sections and strip whitespace\n",
    "    sections = [section.strip() for section in sections if section.strip()]\n",
    "    \n",
    "    # If the first section doesn't start with \"Batch\", it's a header section\n",
    "    if sections and not sections[0].startswith('Batch'):\n",
    "        header = sections[0]\n",
    "        sections = sections[1:]  # Remove the header from sections\n",
    "    else:\n",
    "        header = None\n",
    "    \n",
    "    return sections\n",
    "\n",
    "\n",
    "def extract_epoch_data(section):\n",
    "    epoch_pattern = r'Epoch (\\d+).*, loss: ([\\d.]+), lr: ([\\d.e-]+), Post active train Correct (\\d+), incorrect (\\d+), loss: ([\\d.]+)'\n",
    "    matches = re.findall(epoch_pattern, section)\n",
    "    \n",
    "    data = []\n",
    "    for match in matches:\n",
    "        data.append({\n",
    "            'epoch': int(match[0]),\n",
    "            'training_loss': float(match[1]),\n",
    "            'learning_rate': float(match[2]),\n",
    "            'correct': int(match[3]),\n",
    "            'incorrect': int(match[4]),\n",
    "            'post_train_loss': float(match[5])\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def extract_rank_data(section):\n",
    "    \"\"\"\n",
    "    Extract rank, vote weight, and diff information from a log section.\n",
    "    \n",
    "    Args:\n",
    "        section (str): Log section text containing rank information\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns ['rank', 'vote_weight', 'diff_positions', 'diff_values']\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to match rank information\n",
    "    rank_pattern = r'Rank: (\\d+), Vote weight: ([\\d.]+),.* Diff: \\[(.*?)\\]'\n",
    "    \n",
    "    # Find all matches in the section\n",
    "    matches = re.findall(rank_pattern, section)\n",
    "\n",
    "    data = []\n",
    "    for match in matches:\n",
    "        rank = int(match[0])\n",
    "        vote_weight = float(match[1])\n",
    "        \n",
    "        # Parse the diff information\n",
    "        diff_str = match[2]\n",
    "        diff_positions = []\n",
    "        diff_values = []\n",
    "        \n",
    "        if diff_str:\n",
    "            # Split the diff string into individual tuples\n",
    "            diff_items = re.findall(r'\\((\\d+), (\\d+).*\\)', diff_str)\n",
    "            for pos, val in diff_items:\n",
    "                diff_positions.append(int(pos))\n",
    "                diff_values.append(int(val))\n",
    "        \n",
    "        data.append({\n",
    "            'rank': rank,\n",
    "            'vote_weight': vote_weight,\n",
    "            'diff_positions': diff_positions,\n",
    "            'diff_values': diff_values\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    rank_df = pd.DataFrame(data)\n",
    "    # display(rank_df)\n",
    "    return rank_df\n",
    "\n",
    "def analyze_section(section, section_num):\n",
    "    if 'skip adaptive training' in section:\n",
    "        return {\n",
    "            'correct_and_skip': True\n",
    "        }\n",
    "    if 'OutOfMemoryError!' in section:\n",
    "        return {\n",
    "            'oom': True\n",
    "        }        \n",
    "    # Extract initial batch information\n",
    "    batch_info = re.search(r'BATCH NO\\.(\\d+), shape: \\[([^\\]]+)\\]', section)\n",
    "    if batch_info:\n",
    "        batch_num = batch_info.group(1)\n",
    "        batch_shape = batch_info.group(2)\n",
    "    else:\n",
    "        batch_num = \"Unknown\"\n",
    "        batch_shape = \"Unknown\"\n",
    "    \n",
    "    # Extract epoch data\n",
    "    epoch_df = extract_epoch_data(section)\n",
    "    rank_df = extract_rank_data(section)\n",
    "    \n",
    "    if epoch_df.empty:\n",
    "        return None\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    epoch_df['accuracy'] = epoch_df['correct'] / (epoch_df['correct'] + epoch_df['incorrect'])\n",
    "    \n",
    "    return {\n",
    "        'section_num': section_num,\n",
    "        'batch_num': batch_num,\n",
    "        'batch_shape': batch_shape,\n",
    "        'epoch_data': epoch_df,\n",
    "        'rank_data': rank_df\n",
    "    }\n",
    "\n",
    "def plot_section_metrics(section_data):\n",
    "    if section_data is None or section_data['epoch_data'].empty:\n",
    "        return\n",
    "    \n",
    "    df = section_data['epoch_data']\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Plot training loss and post-train loss\n",
    "    ax1.plot(df['epoch'], df['training_loss'], label='Training Loss')\n",
    "    ax1.plot(df['epoch'], df['post_train_loss'], label='Post-train Loss')\n",
    "    ax1.set_title(f\"Section {section_data['section_num']} (Batch {section_data['batch_num']}) - Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax2.plot(df['epoch'], df['accuracy'])\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Plot learning rate\n",
    "    ax3.plot(df['epoch'], df['learning_rate'])\n",
    "    ax3.set_title('Learning Rate')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_content(content):\n",
    "    # Main execution\n",
    "    sections = split_into_sections(content)\n",
    "    \n",
    "    print(f\"Found {len(sections)} training sections\")\n",
    "    \n",
    "    # Analyze each section\n",
    "    \n",
    "    has_right_answer_count = 0\n",
    "    has_right_answer_exist_in_top_2_ranks = 0\n",
    "    correct_and_skip_count = 0\n",
    "    oom_count = 0\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        section_data = analyze_section(section, i+1)\n",
    "        if section_data:\n",
    "            if 'correct_and_skip' in section_data:\n",
    "                correct_and_skip_count += 1\n",
    "            if 'oom' in section_data:\n",
    "                oom_count += 1\n",
    "            elif 'rank_data' in section_data:\n",
    "                rank_df = section_data['rank_data']\n",
    "                if 'diff_values' in rank_df:\n",
    "                    right_answer_exist = (rank_df['diff_values'].apply(len) == 0).any()\n",
    "                    if right_answer_exist:\n",
    "                        has_right_answer_count += 1\n",
    "    \n",
    "                    right_answer_exist_in_top_2_ranks = (rank_df[rank_df['rank']<=1]['diff_values'].apply(len) == 0).any()\n",
    "                    if right_answer_exist_in_top_2_ranks:\n",
    "                        has_right_answer_exist_in_top_2_ranks += 1\n",
    "    \n",
    "    print('has_right_answer_count', has_right_answer_count, 'has_right_answer_exist_in_top_2_ranks', has_right_answer_exist_in_top_2_ranks, has_right_answer_exist_in_top_2_ranks/len(sections)*100, 'correct_and_skip_count', correct_and_skip_count, correct_and_skip_count/len(sections)*100, 'oom_count', oom_count, 'over', len(sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11004922-6a69-4fae-94a0-1f6f846e67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../meta_training_2500_c15.log\" # \"../meta_training_c15.log\" # \n",
    "analyze_content(read_log_file(file_path))\n",
    "\n",
    "file_path = \"../meta_training_2500_c29.log\" # 2500\n",
    "analyze_content(read_log_file(file_path))\n",
    "\n",
    "file_path = \"../meta_training_2500_c30.log\" # 2500\n",
    "analyze_content(read_log_file(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a01c7-1576-44e1-ace8-8f41332d3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../meta_training_c15_b15.log\"\n",
    "analyze_content(read_log_file(file_path))\n",
    "\n",
    "file_path = \"../meta_training_c15_b8_complete.log\"\n",
    "analyze_content(read_log_file(file_path))\n",
    "\n",
    "file_path = \"../meta_training_c15_b8_complete[:234].log\"\n",
    "analyze_content(read_log_file(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d92695-d9b6-4cab-8d58-a32ac9155515",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../meta_training_fv_c29.log\"\n",
    "analyze_content(read_log_file(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02639540-90e8-463f-82df-d55462251e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../meta_training_fv_c29.log\"\n",
    "analyze_content(read_log_file(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ddadd3-6212-45cd-a683-a312f5a40c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../meta_training_2500_c30[:156].log\"\n",
    "analyze_content(read_log_file(file_path))\n",
    "\n",
    "file_path = \"../meta_training_bark[:156].log\"\n",
    "analyze_content(read_log_file(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc726211-ab7a-4630-9a6a-7d2751e385e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"../meta_training_2500_c30[:86].log\"\n",
    "# analyze_content(read_log_file(file_path))\n",
    "\n",
    "file_path = \"../meta_training_reverse_aug.log\"\n",
    "analyze_content(read_log_file(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
